{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb83553-908e-43fc-b30a-2c91dfda3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ecb24d-a83e-46dd-8b3d-60a042041abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt api í‚¤\n",
    "key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec5f806-9f8f-4b14-a974-01e20a587ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc229b3-a2a3-4df4-8c32-ec698cf3c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©í•  ì—”ì§„\n",
    "model_engine = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9be7ca-d95d-425f-801c-5c8e7625717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜Š ì•ˆë…•, ì´ëª…í›ˆì´!\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ë‚´ìš©\n",
    "prompt = 'Feel : Smile ì•ˆë…• ë‚˜ëŠ” ì´ëª…í›ˆì´ë¼ê³  í•´ '\n",
    "\n",
    "result = client.chat.completions.create(\n",
    "    model = model_engine,\n",
    "    max_tokens = 50, # ìµœëŒ€ ë‹¨ì–´ìˆ˜\n",
    "    messages = [\n",
    "        # ì§ˆë¬¸í•˜ëŠ” ìƒí™©\n",
    "        {'role':'system','content':'ê°ì •ì„ ì´ëª¨ì§€ì™€ ì´ë¦„ê³¼ ëŠë‚Œí‘œë¡œ í‘œí˜„í•©ë‹ˆë‹¤'},\n",
    "        # ì§ˆë¬¸ ë‚´ìš©\n",
    "        {'role':'user','content':prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aff0425-fd9b-41a8-952c-b3c340699053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì •ìƒí™©ì—ì„œ ëŒ€ë‹µí•  íŠ¹ì • ì–‘ì‹ì„ í•™ìŠµì‹œì¼œë³´ì\n",
    "\n",
    "# ì§ˆë¬¸ = 'Feel : Smile ë‚´ ì´ë¦„ì€ ì´ëª…í›ˆì´ë¼ê³ í•´'\n",
    "# ì²« ëŒ€ë‹µ = ğŸ˜Š ì•ˆë…• ì´ëª…í›ˆ!! \n",
    "# ì›í•˜ëŠ” ëŒ€ë‹µ = :) ã…ã… ì´ëª…í›ˆ!\n",
    "\n",
    "# ì§ˆë¬¸ = 'Feel : Sad ë‚´ ì´ë¦„ì€ ì´ëª…í›ˆì´ë¼ê³ í•´'\n",
    "# ì›í•˜ëŠ” ëŒ€ë‹µ = :( ã…œã…œ ì´ëª…í›ˆ! \n",
    "\n",
    "# íŠ¹ì • ì–‘ì‹ìœ¼ë¡œ ëŒ€ë‹µì„ ìœ ë„í•  ìˆ˜ ìˆë‹¤.\n",
    "# íŠ¹ì • ê°’ìœ¼ë¡œ ëŒ€ë‹µì„ ìœ ë„í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e249f768-f066-49c5-98ef-8b7f4ee41369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-gemiWb9h6kkiV6Zd0GejewL3', bytes=3358, created_at=1716795150, filename='data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì¶”ê°€ í•™ìŠµì´ í•„ìš” \n",
    "# í•™ìŠµí•  ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ì•¼ í•¨ > íŠ¹ì • ìƒí™©ì—ì„œ íŠ¹ì • ë¬¼ìŒì— í•´ì•¼í•˜ëŠ” íŠ¹ì • ëŒ€ë‹µ\n",
    "# data.jsonl íŒŒì¼ì— í•™ìŠµë‚´ìš© ë‹´ê²¨ìˆìŒ\n",
    "\n",
    "# í•™ìŠµ ìë£Œ ì—…ë¡œë“œ\n",
    "client.files.create(\n",
    "    file = open('data.jsonl','rb'),\n",
    "    purpose = 'fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f6e1bc1-8ff7-421f-819a-d23d14a8e7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-w2xkyng46ShMy8MNhwIaoU28', created_at=1716795163, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-0eGfjWotkvKSTc6Kxnk4A7hH', result_files=[], seed=245737615, status='validating_files', trained_tokens=None, training_file='file-gemiWb9h6kkiV6Zd0GejewL3', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì¶”ê°€í•™ìŠµ(fine-tuning)\n",
    "client.fine_tuning.jobs.create(\n",
    "    training_file = 'file-gemiWb9h6kkiV6Zd0GejewL3',\n",
    "    model = model_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8141f86e-3ec8-48c1-a907-f4f3ba4aeeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-w2xkyng46ShMy8MNhwIaoU28', created_at=1716795163, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-0eGfjWotkvKSTc6Kxnk4A7hH', result_files=[], seed=245737615, status='validating_files', trained_tokens=None, training_file='file-gemiWb9h6kkiV6Zd0GejewL3', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•™ìŠµ ê³¼ì • í™•ì¸\n",
    "# status='validating_files' íŒŒì¼í™•ì¸ì¤‘\n",
    "# status = 'queued' ëŒ€ê¸°ì¤‘\n",
    "# status = 'running' ì‹¤í–‰ì¤‘\n",
    "# status = 'succeeded' ì™„ë£Œ\n",
    "client.fine_tuning.jobs.retrieve('ftjob-w2xkyng46ShMy8MNhwIaoU28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85b6f96e-27f8-410b-a54a-0988010075b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_model = 'ft:gpt-3.5-turbo-0125:personal::9TOxqw2G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03916bc4-9c11-403f-b42b-b65b3614fecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":( ã…œã…œ ìµœì˜í™”!\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ë‚´ìš©\n",
    "prompt = 'Feel : Sad ì•ˆë…• ë‚˜ëŠ” ìµœì˜í™”ë¼ê³  í•´ '\n",
    "\n",
    "result = client.chat.completions.create(\n",
    "    model = fine_tuning_model,\n",
    "    max_tokens = 50, # ìµœëŒ€ ë‹¨ì–´ìˆ˜\n",
    "    messages = [\n",
    "        # ì§ˆë¬¸í•˜ëŠ” ìƒí™©\n",
    "        {'role':'system','content':'ê°ì •ì„ ì´ëª¨ì§€ì™€ ì´ë¦„ê³¼ ëŠë‚Œí‘œë¡œ í‘œí˜„í•©ë‹ˆë‹¤'},\n",
    "        # ì§ˆë¬¸ ë‚´ìš©\n",
    "        {'role':'user','content':prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710c618-55ac-4fee-9ac8-cd77396d86b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfc4fb-b885-4eeb-a56b-be69158f56fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac31e6-6d21-458c-b78d-f78d2bd45422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee8b0d-1849-45b5-a1a4-ed49099e5f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
